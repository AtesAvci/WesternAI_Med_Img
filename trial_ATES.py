# -*- coding: utf-8 -*-
"""trial_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SD0AT9MnGYRjWsWb6F5iesuhJcoA04ME
"""

#####actual program huh
#####importing
import os
from IPython.display import Image, display
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow import keras
from keras.preprocessing.image import load_img, ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, Conv1D,MaxPooling2D, Dropout
from keras import regularizers
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.naive_bayes import GaussianNB


def main():
      #looking for a path
    train_path = Path('chest_xray/train')
    val_path = Path('chest_xray/val')
    test_path = Path('chest_xray/test')
    print(test_path)

    #Parameters:
    TRIAL = 3
    BATCH_SIZE= 1
    TARGET_SIZE= 64
    CONV_1= 32
    CONV_2 = 32
    DENSE_1 = 1
    DENSE_2 = 2
    DROP_O_1 = 0.2
    DROP_O_2 = 0.2
    EPOCH = 1
    S_PER_EPOCH = 1

    test_norm = ImageDataGenerator(rescale = 1./255)  #Image normalization

    train_batch = test_norm.flow_from_directory(train_path,target_size = (TARGET_SIZE, TARGET_SIZE),classes = ['NORMAL','PNEUMONIA'],batch_size = BATCH_SIZE)
    test_batch = test_norm.flow_from_directory(test_path,target_size = (TARGET_SIZE, TARGET_SIZE),classes = ['NORMAL','PNEUMONIA'],batch_size=32)
    val_batch = test_norm.flow_from_directory(val_path,target_size = (TARGET_SIZE, TARGET_SIZE),classes = ['NORMAL','PNEUMONIA'],batch_size=4)

    #neural network model building
    classifier = Sequential()

    classifier.add(Conv2D(CONV_1, (3,3), input_shape=(TARGET_SIZE, TARGET_SIZE, 3), activation='relu'))
    classifier.add(MaxPooling2D(pool_size=(3,3)))
    classifier.add(Conv2D(CONV_2, (3,3), activation='relu'))
    classifier.add(MaxPooling2D(pool_size=(3,3)))

    classifier.add(Flatten())

    classifier.add(Dropout(DROP_O_1))
    classifier.add(Dense(DENSE_1, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(60,)))
    classifier.add(Dropout(DROP_O_2))
    classifier.add(Dense(DENSE_2, activation='softmax'))


    classifier.summary()

    #network compiling
    classifier.compile(loss = keras.losses.binary_crossentropy, optimizer = 'adam',metrics=['accuracy'])
    history = classifier.fit(train_batch, epochs = EPOCH, steps_per_epoch = S_PER_EPOCH ,validation_data=val_batch,validation_steps=4)


    #printing overall accuracy
    test_acc = classifier.evaluate(test_batch,steps=20)
    print("Test accuracy is: ", test_acc[1]*100, '%' )

    #graphs

    #accuracy
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Training set', 'Validation set'], loc='upper left')
    plt.show()

    #loss
    plt.plot(history.history['val_loss'])
    plt.plot(history.history['loss'])
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Training set', 'Test set'], loc='upper left')
    plt.show()

    store("Storage", TRIAL, BATCH_SIZE, TARGET_SIZE, CONV_1, CONV_2, DENSE_1, DENSE_2, DROP_O_1,
          DROP_O_2, EPOCH, S_PER_EPOCH, history.history['accuracy'], test_acc[1]*100, history.history['val_accuracy'] )
                                                                                    

       
def store(file, trial, batch_size, target_size, conv_1, conv_2, dense_1, dense_2, drO1, drO2, epoch, steps, train_ac, test_ac, val_ac):

    try:
        outF = open(file, "a")

        space = [6-l_int(trial), 12-l_int(batch_size), 13-l_int(target_size), 14-l_int(conv_1)-l_int(conv_2), 9-l_int(dense_1)-l_int(dense_2),
        12-l_int(drO1)-l_int(drO2), 10-l_int(epoch)-l_int(steps), 16-l_int(train_ac)-l_int(test_ac)-l_int(val_ac)]

        outF.write(str(trial) + " "*space[0] + "|  " + str(batch_size) + " "*space[1] + "|  " + str(target_size) + " "*space[2] + "|  "
         + str(conv_1) + ", " + str(conv_2) + " "*space[3] + "|  " + str(dense_1) + ", " + str(dense_2) + " "*space[4] + "|  "
         + str(drO1) + ", " + str(drO2) + " "*space[5] + "|  " + str(epoch) +
        ", " + str(steps) + " "*space[6] + "|  " + str(train_ac) + ", " + str(round(test_ac,2)) + ", " + str(val_ac)  + " "*space[7] + "|  ")

    except IOError as File:
             print("{} does not exist").format(File)
    finally:
        outF.close()

def l_int(int):
    res = len(str(int))
    return res

main()
