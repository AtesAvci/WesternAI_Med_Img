# -*- coding: utf-8 -*-
"""trial_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SD0AT9MnGYRjWsWb6F5iesuhJcoA04ME
"""

#####actual program huh
#####importing
import os
from IPython.display import Image, display
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow import keras
from keras.preprocessing.image import load_img, ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, Conv1D,MaxPooling2D
import matplotlib.pyplot as plt

#looking for an path in Google drive
train_path = ''
val_path = ''
test_path = ''

test_norm = ImageDataGenerator(rescale = 1./255)  #Image normalization

#transofrming images into matrices to work with; batch size = 30
train_batch = test_norm.flow_from_directory(train_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)
test_batch = test_norm.flow_from_directory(test_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)
val_batch = test_norm.flow_from_directory(val_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)

#neural network model building
classifier = Sequential()

classifier.add(Conv2D(80, (3,3), input_shape=(500, 500, 3), activation='relu', strides= 2))
classifier.add(MaxPooling2D(pool_size=(3,3)))
classifier.add(Conv2D(80, (3,3), activation='relu', strides= 2))
classifier.add(MaxPooling2D(pool_size=(3,3)))

classifier.add(Flatten())

#classifier.add(Dense(50, activation='relu'))
classifier.add(Dense(128, activation='relu'))
classifier.add(Dense(128, activation='relu'))
classifier.add(Dense(2, activation='softmax'))
classifier.summary()

#network compiling
classifier.compile(loss = keras.losses.binary_crossentropy, optimizer = 'adam',metrics=['accuracy'])

#it is stored in history, since it works out for graphics
history = classifier.fit(train_batch,epochs = 5, steps_per_epoch=15,validation_data=val_batch,validation_steps=5)



#printing overall accuracy

#not sure whether it should be history or classifier here
test_accu = classifier.evaluate_generator(test_batch,steps=10)
print("Test accuracy is: ", test_accu[1]*100, '%' )



#graphs 

#accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training set', 'Validation set'], loc='upper left')
plt.show()

#loss
plt.plot(history.history['val_loss'])
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training set', 'Test set'], loc='upper left')
plt.show()
